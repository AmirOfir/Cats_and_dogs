{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Identify dog or cat - Tryout 4","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"BDTI-cITpEZk","colab_type":"text"},"source":["#Tryout #4\n","Dropped learning data size to 10000 each class"]},{"cell_type":"code","metadata":{"id":"RFIZbRk4o1RC","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"d900519f-4b31-4982-fa79-a29b412100d3","executionInfo":{"status":"ok","timestamp":1570948818973,"user_tz":-180,"elapsed":1781,"user":{"displayName":"אמיר טיולים אופיר","photoUrl":"","userId":"10553102954387448326"}}},"source":["import sys\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","#from torch.autograd import Function\n","from torchvision import transforms, datasets\n","# import math\n","\n","import torch.nn.functional as F\n","# import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader, ConcatDataset\n","# import copy\n","import tqdm\n","from PIL import Image\n","\n","# Load the data (extract)\n","import os\n","import zipfile\n","from pathlib import Path\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"y7HxizC1sW4f","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":84},"outputId":"65ffe4c4-d4a4-4a91-b4c8-ae3f732c4a64","executionInfo":{"status":"ok","timestamp":1570948860170,"user_tz":-180,"elapsed":17401,"user":{"displayName":"אמיר טיולים אופיר","photoUrl":"","userId":"10553102954387448326"}}},"source":["if not (os.path.exists('tmp/train')):\n","  local_zip = '/content/drive/My Drive/datasets/dogscats/train.zip'\n","  zip_ref = zipfile.ZipFile(local_zip, 'r')\n","  zip_ref.extractall('/tmp')\n","  zip_ref.close()\n","  local_zip = '/content/drive/My Drive/datasets/dogscats/test.zip'\n","  zip_ref = zipfile.ZipFile(local_zip, 'r')\n","  zip_ref.extractall('/tmp')\n","  zip_ref.close()\n","import gc\n","gc.collect()\n","\n","base_dir = '/tmp'\n","train_dir = os.path.join(base_dir, 'train')\n","validation_dir = os.path.join(base_dir, 'test1')\n","\n","train_fnames = os.listdir(train_dir)\n","validation_fnames = os.listdir(validation_dir)\n","\n","train_cat_fnames = [os.path.join(train_dir, x) for x in train_fnames if x.startswith('cat')][:-2500]\n","train_dog_fnames = [os.path.join(train_dir, x) for x in train_fnames if x.startswith('dog')][:-2500]\n","validation_cat_fnames = [os.path.join(train_dir, x) for x in train_fnames if x.startswith('cat')][-500:]\n","validation_dog_fnames = [os.path.join(train_dir, x) for x in train_fnames if x.startswith('dog')][-500:]\n","\n","del train_fnames\n","del validation_fnames\n","print('total training cat images:', len(train_cat_fnames))\n","print('total training dog images:', len(train_dog_fnames))\n","print('total validation cat images:', len(validation_cat_fnames))\n","print('total validation dog images:', len(validation_dog_fnames))"],"execution_count":2,"outputs":[{"output_type":"stream","text":["total training cat images: 10000\n","total training dog images: 10000\n","total validation cat images: 500\n","total validation dog images: 500\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Gr_z9C2ZsXfT","colab_type":"code","colab":{}},"source":["\n","class CatDogDataset(Dataset):\n","    def __init__(self, file_list, label=-1, mode='train', transform = None):\n","        self.file_list = file_list\n","        self.label = label\n","        self.mode = mode\n","        self.transform = transform\n","        \n","    def __len__(self):\n","        return len(self.file_list)\n","    \n","    def __getitem__(self, idx):\n","        img = Image.open(self.file_list[idx])\n","        img\n","        if self.transform:\n","            img = self.transform(img)\n","            \n","        if self.mode == 'train':\n","            img = img.numpy()\n","            return img.astype('float32'), self.label\n","        else:\n","            img = img.numpy()\n","            return img.astype('float32'), self.label #file_list[idx]\n","        \n","data_transform = transforms.Compose([\n","    transforms.Resize((45,45)),\n","    transforms.Resize((450,450)),\n","    transforms.Grayscale(),\n","    transforms.ToTensor()\n","])\n","\n","train_cats_ds = CatDogDataset(train_cat_fnames, 0, transform = data_transform)\n","train_dogs_ds = CatDogDataset(train_dog_fnames, 1, transform = data_transform)\n","\n","train_catdogs_ds = ConcatDataset([train_cats_ds, train_dogs_ds])\n","dataloader = DataLoader(train_catdogs_ds, batch_size = 32, shuffle=True, num_workers=0)\n","\n","validation_cats = CatDogDataset(validation_cat_fnames, 0, transform = data_transform)\n","validation_dogs = CatDogDataset(validation_dog_fnames, 1, transform = data_transform)\n","\n","validation_catdogs = ConcatDataset([validation_cats, validation_dogs])\n","validation_size = len(validation_cat_fnames) + len(validation_dog_fnames)\n","validation_dataloader = DataLoader(validation_catdogs, batch_size = int(validation_size / 100), shuffle=False, num_workers=0)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EenhWo36selb","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"c940e72a-8ae3-4c95-fadc-5aaa24b8ac61","executionInfo":{"status":"ok","timestamp":1570948863596,"user_tz":-180,"elapsed":619,"user":{"displayName":"אמיר טיולים אופיר","photoUrl":"","userId":"10553102954387448326"}}},"source":["samples, labels = iter(dataloader).next()\n","print(samples.shape)\n","\n","def test():\n","  model.eval()\n","  test_loss = 0\n","  correct = 0\n","  with torch.no_grad():\n","      for data, target in validation_dataloader:\n","          data, target = data.to(device), target.to(device)\n","          output = model(data)\n","          test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n","          pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n","          correct += pred.eq(target.view_as(pred)).sum().item()\n","  test_loss /= len(validation_dataloader.dataset)\n","\n","  print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n","      test_loss, correct, len(validation_dataloader.dataset),\n","      100. * correct / len(validation_dataloader.dataset)))\n","  return 100. * correct / len(validation_dataloader.dataset)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["torch.Size([32, 1, 450, 450])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"N5fYJ8AhsixC","colab_type":"code","colab":{}},"source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","class Net(nn.Module):\n","  def __init__(self):\n","    super(Net, self).__init__()\n","    addition = 20\n","\n","    self.cl1 = nn.Conv2d(1,32,3,1,padding=2)\n","    self.cl2 = nn.Conv2d(32,32,3,1,padding=1)\n","    self.cl3 = nn.Conv2d(32,64,3,1,padding=1)\n","    self.cl4 = nn.Conv2d(64,64,3,1,padding=1)\n","    self.cl5 = nn.Conv2d(64,128,3,1,padding=1)\n","    self.cl6 = nn.Conv2d(128,128,3,1,padding=1)\n","    self.cl7 = nn.Conv2d(128,256,3,1,padding=1)\n","    self.cl8 = nn.Conv2d(256,256,3,1,padding=1)\n","    self.fc1 = nn.Linear(256 * (28**2), 256)\n","    self.fc2 = nn.Linear(256, 256)\n","    self.fc3 = nn.Linear(256, 10)\n","  def forward(self, x): \n","    x = F.relu(self.cl1(x))\n","    # print(x.shape)\n","    x = F.relu(self.cl2(x))\n","    # print(x.shape)\n","    x = F.max_pool2d(x, 2, 2)\n","    # print(x.shape)\n","    x = F.relu(self.cl3(x))\n","    # print(x.shape)\n","    x = F.relu(self.cl4(x))\n","    # print(x.shape)\n","    x = F.max_pool2d(x, 2, 2)\n","    # print(x.shape)\n","    x = F.relu(self.cl5(x))\n","    # print(x.shape)\n","    x = F.relu(self.cl6(x))\n","    # print(x.shape)\n","    x = F.max_pool2d(x, 2, 2)\n","    # print(x.shape)\n","    x = F.relu(self.cl7(x))\n","    # print(x.shape)\n","    x = F.relu(self.cl8(x))\n","    # print(x.shape)\n","    x = F.max_pool2d(x, 2, 2)\n","    # print(x.shape)\n","    x = x.view(-1, self.fc1.in_features)\n","    x = F.relu(self.fc1(x))\n","    x = F.dropout2d(x)\n","    x = F.relu(self.fc2(x))\n","    x = F.dropout2d(x)\n","    x = self.fc3(x)\n","    x = torch.sigmoid(x) # used dim=1 to work on the data not on the batch\n","    return x\n","model = Net().to(device)\n","model = model.to(device)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.RMSprop(model.parameters(), lr=0.0001)#.Adam(model.parameters(), lr=0.002, amsgrad=True)\n","scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[500,1000,1500], gamma=0.5)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kPGUxCtM1qgL","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"d2f537f1-f40c-4f14-a88e-0592f5341a38","executionInfo":{"status":"ok","timestamp":1570949601450,"user_tz":-180,"elapsed":803,"user":{"displayName":"אמיר טיולים אופיר","photoUrl":"","userId":"10553102954387448326"}}},"source":["gc.collect()"],"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"code","metadata":{"id":"fJoagaS_slLi","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"21b05930-3869-4b9b-85d3-ce2f81903c09"},"source":["epochs = 20\n","itr = 1\n","p_itr = 10\n","total_loss = 0\n","loss_list = []\n","acc_list = []\n","for epoch in range(epochs):\n","    gc.collect()\n","    model.train()\n","    for samples, labels in dataloader:\n","        samples, labels = samples.to(device), labels.to(device)\n","        optimizer.zero_grad()\n","        output = model(samples)\n","        loss = criterion(output, labels)\n","        loss.backward()\n","        optimizer.step()\n","        total_loss += loss.item()\n","        scheduler.step()\n","        \n","        if itr%p_itr == 0:\n","            pred = torch.argmax(output, dim=1)\n","            correct = pred.eq(labels)\n","            acc = torch.mean(correct.float())\n","            print('[Epoch {}/{}] Iteration {} -> Train Loss: {:.4f}, Accuracy: {:.3f}'.format(epoch+1, epochs, itr, total_loss/p_itr, acc))\n","            loss_list.append(total_loss/p_itr)\n","            acc_list.append(acc)\n","            total_loss = 0\n","            \n","        itr += 1\n","    acc = test()\n","    torch.save(model.state_dict(),\"/content/drive/My Drive/datasets/dogscats/cnn3.pt\")\n","    if (acc > 85):\n","      break\n","    for param_group in optimizer.param_groups:\n","      param_group['lr'] = param_group['lr'] * 0.95\n","print(itr)\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[Epoch 1/20] Iteration 10 -> Train Loss: 1.7531, Accuracy: 0.750\n","[Epoch 1/20] Iteration 20 -> Train Loss: 1.6116, Accuracy: 0.531\n","[Epoch 1/20] Iteration 30 -> Train Loss: 1.6065, Accuracy: 0.438\n","[Epoch 1/20] Iteration 40 -> Train Loss: 1.6042, Accuracy: 0.562\n","[Epoch 1/20] Iteration 50 -> Train Loss: 1.6087, Accuracy: 0.562\n","[Epoch 1/20] Iteration 60 -> Train Loss: 1.6029, Accuracy: 0.344\n","[Epoch 1/20] Iteration 70 -> Train Loss: 1.6014, Accuracy: 0.500\n","[Epoch 1/20] Iteration 80 -> Train Loss: 1.6004, Accuracy: 0.469\n","[Epoch 1/20] Iteration 90 -> Train Loss: 1.6021, Accuracy: 0.469\n","[Epoch 1/20] Iteration 100 -> Train Loss: 1.5995, Accuracy: 0.500\n","[Epoch 1/20] Iteration 110 -> Train Loss: 1.5995, Accuracy: 0.531\n","[Epoch 1/20] Iteration 120 -> Train Loss: 1.5981, Accuracy: 0.562\n","[Epoch 1/20] Iteration 130 -> Train Loss: 1.6015, Accuracy: 0.375\n","[Epoch 1/20] Iteration 140 -> Train Loss: 1.5983, Accuracy: 0.531\n","[Epoch 1/20] Iteration 150 -> Train Loss: 1.5991, Accuracy: 0.594\n","[Epoch 1/20] Iteration 160 -> Train Loss: 1.6015, Accuracy: 0.594\n","[Epoch 1/20] Iteration 170 -> Train Loss: 1.5986, Accuracy: 0.562\n","[Epoch 1/20] Iteration 180 -> Train Loss: 1.5975, Accuracy: 0.500\n","[Epoch 1/20] Iteration 190 -> Train Loss: 1.5984, Accuracy: 0.500\n","[Epoch 1/20] Iteration 200 -> Train Loss: 1.5996, Accuracy: 0.531\n","[Epoch 1/20] Iteration 210 -> Train Loss: 1.5985, Accuracy: 0.406\n","[Epoch 1/20] Iteration 220 -> Train Loss: 1.5987, Accuracy: 0.406\n","[Epoch 1/20] Iteration 230 -> Train Loss: 1.6004, Accuracy: 0.531\n","[Epoch 1/20] Iteration 240 -> Train Loss: 1.6010, Accuracy: 0.531\n","[Epoch 1/20] Iteration 250 -> Train Loss: 1.5984, Accuracy: 0.406\n","[Epoch 1/20] Iteration 260 -> Train Loss: 1.6009, Accuracy: 0.344\n","[Epoch 1/20] Iteration 270 -> Train Loss: 1.5987, Accuracy: 0.500\n","[Epoch 1/20] Iteration 280 -> Train Loss: 1.5987, Accuracy: 0.594\n","[Epoch 1/20] Iteration 290 -> Train Loss: 1.5987, Accuracy: 0.531\n","[Epoch 1/20] Iteration 300 -> Train Loss: 1.5983, Accuracy: 0.375\n","[Epoch 1/20] Iteration 310 -> Train Loss: 1.6010, Accuracy: 0.438\n","[Epoch 1/20] Iteration 320 -> Train Loss: 1.5990, Accuracy: 0.531\n","[Epoch 1/20] Iteration 330 -> Train Loss: 1.5984, Accuracy: 0.562\n","[Epoch 1/20] Iteration 340 -> Train Loss: 1.5979, Accuracy: 0.469\n","[Epoch 1/20] Iteration 350 -> Train Loss: 1.5988, Accuracy: 0.438\n","[Epoch 1/20] Iteration 360 -> Train Loss: 1.5989, Accuracy: 0.312\n","[Epoch 1/20] Iteration 370 -> Train Loss: 1.5984, Accuracy: 0.469\n","[Epoch 1/20] Iteration 380 -> Train Loss: 1.5980, Accuracy: 0.625\n","[Epoch 1/20] Iteration 390 -> Train Loss: 1.5986, Accuracy: 0.438\n","[Epoch 1/20] Iteration 400 -> Train Loss: 1.5982, Accuracy: 0.562\n","[Epoch 1/20] Iteration 410 -> Train Loss: 1.5980, Accuracy: 0.562\n","[Epoch 1/20] Iteration 420 -> Train Loss: 1.5982, Accuracy: 0.625\n","[Epoch 1/20] Iteration 430 -> Train Loss: 1.6019, Accuracy: 0.219\n","[Epoch 1/20] Iteration 440 -> Train Loss: 1.5984, Accuracy: 0.406\n","[Epoch 1/20] Iteration 450 -> Train Loss: 1.5981, Accuracy: 0.562\n","[Epoch 1/20] Iteration 460 -> Train Loss: 1.5980, Accuracy: 0.469\n","[Epoch 1/20] Iteration 470 -> Train Loss: 1.6003, Accuracy: 0.469\n","[Epoch 1/20] Iteration 480 -> Train Loss: 1.5980, Accuracy: 0.406\n","[Epoch 1/20] Iteration 490 -> Train Loss: 1.5980, Accuracy: 0.438\n","[Epoch 1/20] Iteration 500 -> Train Loss: 1.5991, Accuracy: 0.531\n","[Epoch 1/20] Iteration 510 -> Train Loss: 1.5984, Accuracy: 0.625\n","[Epoch 1/20] Iteration 520 -> Train Loss: 1.5984, Accuracy: 0.625\n","[Epoch 1/20] Iteration 530 -> Train Loss: 1.5980, Accuracy: 0.438\n","[Epoch 1/20] Iteration 540 -> Train Loss: 1.5979, Accuracy: 0.562\n","[Epoch 1/20] Iteration 550 -> Train Loss: 1.5986, Accuracy: 0.438\n","[Epoch 1/20] Iteration 560 -> Train Loss: 1.5980, Accuracy: 0.469\n","[Epoch 1/20] Iteration 570 -> Train Loss: 1.5982, Accuracy: 0.531\n","[Epoch 1/20] Iteration 580 -> Train Loss: 1.5980, Accuracy: 0.531\n","[Epoch 1/20] Iteration 590 -> Train Loss: 1.5980, Accuracy: 0.344\n","[Epoch 1/20] Iteration 600 -> Train Loss: 1.5984, Accuracy: 0.438\n","[Epoch 1/20] Iteration 610 -> Train Loss: 1.5980, Accuracy: 0.531\n","[Epoch 1/20] Iteration 620 -> Train Loss: 1.5981, Accuracy: 0.469\n","\n","Test set: Average loss: -0.9990, Accuracy: 501/1000 (50%)\n","\n","[Epoch 2/20] Iteration 630 -> Train Loss: 1.5987, Accuracy: 0.594\n","[Epoch 2/20] Iteration 640 -> Train Loss: 1.5984, Accuracy: 0.594\n","[Epoch 2/20] Iteration 650 -> Train Loss: 1.5980, Accuracy: 0.406\n","[Epoch 2/20] Iteration 660 -> Train Loss: 1.5980, Accuracy: 0.438\n","[Epoch 2/20] Iteration 670 -> Train Loss: 1.6002, Accuracy: 0.406\n","[Epoch 2/20] Iteration 680 -> Train Loss: 1.5987, Accuracy: 0.344\n","[Epoch 2/20] Iteration 690 -> Train Loss: 1.5986, Accuracy: 0.406\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"OnzV48vg23Tc","colab_type":"code","colab":{}},"source":["criterion = nn.CrossEntropyLoss()"],"execution_count":0,"outputs":[]}]}